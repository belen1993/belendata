{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios Pandas DataFrames 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga el dataset de vuelos \"flights14.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dep_delay</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>carrier</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>air_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>AA</td>\n",
       "      <td>JFK</td>\n",
       "      <td>LAX</td>\n",
       "      <td>359</td>\n",
       "      <td>2475</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>13</td>\n",
       "      <td>AA</td>\n",
       "      <td>JFK</td>\n",
       "      <td>LAX</td>\n",
       "      <td>363</td>\n",
       "      <td>2475</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>AA</td>\n",
       "      <td>JFK</td>\n",
       "      <td>LAX</td>\n",
       "      <td>351</td>\n",
       "      <td>2475</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-8</td>\n",
       "      <td>-26</td>\n",
       "      <td>AA</td>\n",
       "      <td>LGA</td>\n",
       "      <td>PBI</td>\n",
       "      <td>157</td>\n",
       "      <td>1035</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>AA</td>\n",
       "      <td>JFK</td>\n",
       "      <td>LAX</td>\n",
       "      <td>350</td>\n",
       "      <td>2475</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  year  month  day  dep_delay  arr_delay carrier origin dest  \\\n",
       "0           1  2014      1    1         14         13      AA    JFK  LAX   \n",
       "1           2  2014      1    1         -3         13      AA    JFK  LAX   \n",
       "2           3  2014      1    1          2          9      AA    JFK  LAX   \n",
       "3           4  2014      1    1         -8        -26      AA    LGA  PBI   \n",
       "4           5  2014      1    1          2          1      AA    JFK  LAX   \n",
       "\n",
       "   air_time  distance  hour  \n",
       "0       359      2475     9  \n",
       "1       363      2475    11  \n",
       "2       351      2475    19  \n",
       "3       157      1035     7  \n",
       "4       350      2475    13  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./flights14.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 253316 entries, 0 to 253315\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  253316 non-null  int64 \n",
      " 1   year        253316 non-null  int64 \n",
      " 2   month       253316 non-null  int64 \n",
      " 3   day         253316 non-null  int64 \n",
      " 4   dep_delay   253316 non-null  int64 \n",
      " 5   arr_delay   253316 non-null  int64 \n",
      " 6   carrier     253316 non-null  object\n",
      " 7   origin      253316 non-null  object\n",
      " 8   dest        253316 non-null  object\n",
      " 9   air_time    253316 non-null  int64 \n",
      " 10  distance    253316 non-null  int64 \n",
      " 11  hour        253316 non-null  int64 \n",
      "dtypes: int64(9), object(3)\n",
      "memory usage: 23.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. escribe un programa Pandas para dividir los datos basados en origen u destino. Muestra cada grupo y el n√∫mero de elementos por grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('EWR', 'ALB') 169\n",
      "('EWR', 'ANC') 13\n",
      "('EWR', 'ATL') 4182\n",
      "('EWR', 'AUS') 568\n",
      "('EWR', 'AVL') 145\n",
      "('EWR', 'AVP') 1\n",
      "('EWR', 'BDL') 210\n",
      "('EWR', 'BNA') 1797\n",
      "('EWR', 'BOS') 4268\n",
      "('EWR', 'BQN') 251\n",
      "('EWR', 'BTV') 300\n",
      "('EWR', 'BUF') 334\n",
      "('EWR', 'BWI') 185\n",
      "('EWR', 'BZN') 51\n",
      "('EWR', 'CAE') 21\n",
      "('EWR', 'CHS') 986\n",
      "('EWR', 'CLE') 1171\n",
      "('EWR', 'CLT') 3921\n",
      "('EWR', 'CMH') 763\n",
      "('EWR', 'CVG') 1187\n",
      "('EWR', 'DAY') 566\n",
      "('EWR', 'DCA') 1309\n",
      "('EWR', 'DEN') 2243\n",
      "('EWR', 'DFW') 2224\n",
      "('EWR', 'DSM') 179\n",
      "('EWR', 'DTW') 2149\n",
      "('EWR', 'EGE') 80\n",
      "('EWR', 'FLL') 2909\n",
      "('EWR', 'GRR') 490\n",
      "('EWR', 'GSO') 644\n",
      "('EWR', 'GSP') 518\n",
      "('EWR', 'HDN') 13\n",
      "('EWR', 'HNL') 301\n",
      "('EWR', 'HOU') 784\n",
      "('EWR', 'IAD') 629\n",
      "('EWR', 'IAH') 3073\n",
      "('EWR', 'IND') 1239\n",
      "('EWR', 'JAC') 19\n",
      "('EWR', 'JAX') 998\n",
      "('EWR', 'LAS') 1555\n",
      "('EWR', 'LAX') 4226\n",
      "('EWR', 'MCI') 995\n",
      "('EWR', 'MCO') 4164\n",
      "('EWR', 'MDT') 5\n",
      "('EWR', 'MDW') 1537\n",
      "('EWR', 'MEM') 660\n",
      "('EWR', 'MHT') 324\n",
      "('EWR', 'MIA') 2094\n",
      "('EWR', 'MKE') 676\n",
      "('EWR', 'MSN') 280\n",
      "('EWR', 'MSP') 1485\n",
      "('EWR', 'MSY') 982\n",
      "('EWR', 'MTJ') 12\n",
      "('EWR', 'OKC') 223\n",
      "('EWR', 'OMA') 544\n",
      "('EWR', 'ORD') 3272\n",
      "('EWR', 'ORF') 211\n",
      "('EWR', 'PBI') 1874\n",
      "('EWR', 'PDX') 418\n",
      "('EWR', 'PHL') 7\n",
      "('EWR', 'PHX') 2002\n",
      "('EWR', 'PIT') 353\n",
      "('EWR', 'PVD') 169\n",
      "('EWR', 'PWM') 392\n",
      "('EWR', 'RDU') 741\n",
      "('EWR', 'RIC') 1183\n",
      "('EWR', 'ROC') 504\n",
      "('EWR', 'RSW') 1160\n",
      "('EWR', 'SAN') 884\n",
      "('EWR', 'SAT') 205\n",
      "('EWR', 'SAV') 557\n",
      "('EWR', 'SBN') 6\n",
      "('EWR', 'SDF') 529\n",
      "('EWR', 'SEA') 1364\n",
      "('EWR', 'SFO') 4539\n",
      "('EWR', 'SJU') 949\n",
      "('EWR', 'SLC') 285\n",
      "('EWR', 'SNA') 657\n",
      "('EWR', 'STL') 1740\n",
      "('EWR', 'STT') 174\n",
      "('EWR', 'SYR') 86\n",
      "('EWR', 'TPA') 1833\n",
      "('EWR', 'TUL') 201\n",
      "('EWR', 'TVC') 20\n",
      "('EWR', 'TYS') 238\n",
      "('EWR', 'XNA') 195\n",
      "('JFK', 'ABQ') 278\n",
      "('JFK', 'ACK') 277\n",
      "('JFK', 'ATL') 1701\n",
      "('JFK', 'AUS') 1370\n",
      "('JFK', 'BNA') 284\n",
      "('JFK', 'BOS') 4111\n",
      "('JFK', 'BQN') 535\n",
      "('JFK', 'BTV') 1004\n",
      "('JFK', 'BUF') 2164\n",
      "('JFK', 'BUR') 289\n",
      "('JFK', 'BWI') 282\n",
      "('JFK', 'CHS') 587\n",
      "('JFK', 'CLE') 280\n",
      "('JFK', 'CLT') 2272\n",
      "('JFK', 'CMH') 576\n",
      "('JFK', 'CVG') 282\n",
      "('JFK', 'DCA') 1686\n",
      "('JFK', 'DEN') 579\n",
      "('JFK', 'DFW') 474\n",
      "('JFK', 'DTW') 198\n",
      "('JFK', 'EGE') 85\n",
      "('JFK', 'FLL') 3258\n",
      "('JFK', 'HNL') 260\n",
      "('JFK', 'HOU') 570\n",
      "('JFK', 'HYA') 75\n",
      "('JFK', 'IAD') 1604\n",
      "('JFK', 'IAH') 7\n",
      "('JFK', 'IND') 278\n",
      "('JFK', 'JAC') 1\n",
      "('JFK', 'JAX') 843\n",
      "('JFK', 'LAS') 3355\n",
      "('JFK', 'LAX') 10208\n",
      "('JFK', 'LGB') 526\n",
      "('JFK', 'MCO') 4467\n",
      "('JFK', 'MIA') 2750\n",
      "('JFK', 'MSP') 458\n",
      "('JFK', 'MSY') 908\n",
      "('JFK', 'MVY') 159\n",
      "('JFK', 'OAK') 247\n",
      "('JFK', 'ORD') 1265\n",
      "('JFK', 'ORF') 282\n",
      "('JFK', 'PBI') 1362\n",
      "('JFK', 'PDX') 725\n",
      "('JFK', 'PHL') 1\n",
      "('JFK', 'PHX') 1784\n",
      "('JFK', 'PIT') 384\n",
      "('JFK', 'PSE') 289\n",
      "('JFK', 'PSP') 17\n",
      "('JFK', 'PWM') 1076\n",
      "('JFK', 'RDU') 1770\n",
      "('JFK', 'ROC') 1036\n",
      "('JFK', 'RSW') 856\n",
      "('JFK', 'SAN') 1402\n",
      "('JFK', 'SAT') 242\n",
      "('JFK', 'SAV') 514\n",
      "('JFK', 'SEA') 1815\n",
      "('JFK', 'SFO') 7368\n",
      "('JFK', 'SJC') 252\n",
      "('JFK', 'SJU') 4027\n",
      "('JFK', 'SLC') 1706\n",
      "('JFK', 'SMF') 246\n",
      "('JFK', 'SRQ') 370\n",
      "('JFK', 'STT') 450\n",
      "('JFK', 'SYR') 937\n",
      "('JFK', 'TPA') 2019\n",
      "('LGA', 'AGS') 3\n",
      "('LGA', 'ATL') 6925\n",
      "('LGA', 'AVL') 2\n",
      "('LGA', 'BGR') 274\n",
      "('LGA', 'BHM') 124\n",
      "('LGA', 'BNA') 2600\n",
      "('LGA', 'BOS') 3230\n",
      "('LGA', 'BTV') 229\n",
      "('LGA', 'BUF') 169\n",
      "('LGA', 'BZN') 15\n",
      "('LGA', 'CAE') 382\n",
      "('LGA', 'CAK') 708\n",
      "('LGA', 'CHO') 329\n",
      "('LGA', 'CHS') 574\n",
      "('LGA', 'CLE') 2111\n",
      "('LGA', 'CLT') 3431\n",
      "('LGA', 'CMH') 1816\n",
      "('LGA', 'CVG') 78\n",
      "('LGA', 'DAL') 15\n",
      "('LGA', 'DAY') 490\n",
      "('LGA', 'DCA') 3753\n",
      "('LGA', 'DEN') 2939\n",
      "('LGA', 'DFW') 3789\n",
      "('LGA', 'DSM') 1\n",
      "('LGA', 'DTW') 3663\n",
      "('LGA', 'EYW') 32\n",
      "('LGA', 'FLL') 3304\n",
      "('LGA', 'GRR') 266\n",
      "('LGA', 'GSO') 868\n",
      "('LGA', 'GSP') 3\n",
      "('LGA', 'HOU') 905\n",
      "('LGA', 'IAD') 1091\n",
      "('LGA', 'IAH') 2346\n",
      "('LGA', 'ILM') 223\n",
      "('LGA', 'IND') 49\n",
      "('LGA', 'JAX') 67\n",
      "('LGA', 'LIT') 204\n",
      "('LGA', 'MCI') 406\n",
      "('LGA', 'MCO') 3078\n",
      "('LGA', 'MDW') 1937\n",
      "('LGA', 'MEM') 3\n",
      "('LGA', 'MHT') 146\n",
      "('LGA', 'MIA') 5084\n",
      "('LGA', 'MKE') 1176\n",
      "('LGA', 'MSN') 188\n",
      "('LGA', 'MSP') 2220\n",
      "('LGA', 'MSY') 738\n",
      "('LGA', 'MYR') 11\n",
      "('LGA', 'OMA') 87\n",
      "('LGA', 'ORD') 7052\n",
      "('LGA', 'ORF') 1014\n",
      "('LGA', 'PBI') 2307\n",
      "('LGA', 'PHL') 702\n",
      "('LGA', 'PIT') 262\n",
      "('LGA', 'PWM') 131\n",
      "('LGA', 'RDU') 2499\n",
      "('LGA', 'RIC') 1135\n",
      "('LGA', 'ROA') 125\n",
      "('LGA', 'ROC') 254\n",
      "('LGA', 'RSW') 569\n",
      "('LGA', 'SAV') 368\n",
      "('LGA', 'SBN') 2\n",
      "('LGA', 'SDF') 542\n",
      "('LGA', 'SRQ') 496\n",
      "('LGA', 'STL') 2065\n",
      "('LGA', 'SYR') 332\n",
      "('LGA', 'TPA') 1852\n",
      "('LGA', 'TVC') 36\n",
      "('LGA', 'TYS') 167\n",
      "('LGA', 'XNA') 441\n"
     ]
    }
   ],
   "source": [
    "gdf = df.groupby(['origin', 'dest'])\n",
    "\n",
    "for g,vals in gdf.groups.items():\n",
    "    print(g, len(vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">EWR</th>\n",
       "      <th>ALB</th>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANC</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATL</th>\n",
       "      <td>4182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUS</th>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVL</th>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">LGA</th>\n",
       "      <th>SYR</th>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPA</th>\n",
       "      <td>1852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TVC</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TYS</th>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XNA</th>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              num\n",
       "origin dest      \n",
       "EWR    ALB    169\n",
       "       ANC     13\n",
       "       ATL   4182\n",
       "       AUS    568\n",
       "       AVL    145\n",
       "...           ...\n",
       "LGA    SYR    332\n",
       "       TPA   1852\n",
       "       TVC     36\n",
       "       TYS    167\n",
       "       XNA    441\n",
       "\n",
       "[221 rows x 1 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.agg({'year':'count'}).rename(columns={'year':'num'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Escribe un programa Pandas para calcula la media, desviaci√≥n est√°ndar, min y max del retraso total de cada orgige-destino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            total_delay                      \n",
      "                   mean         std min   max\n",
      "origin dest                                  \n",
      "EWR    ALB    35.230769   92.478247 -36   618\n",
      "       ANC    15.307692   43.453777 -30   121\n",
      "       ATL    32.235533  114.946191 -47  2177\n",
      "       AUS     5.871479   63.006811 -62   539\n",
      "       AVL    24.903448   82.071727 -33   625\n",
      "...                 ...         ...  ..   ...\n",
      "LGA    SYR    23.346386   88.091602 -54   844\n",
      "       TPA    15.267279   80.570698 -57   964\n",
      "       TVC    71.500000  183.741200 -41   765\n",
      "       TYS    17.305389   57.004937 -44   291\n",
      "       XNA     6.911565   53.977890 -64   320\n",
      "\n",
      "[221 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df['total_delay'] = df['dep_delay']+df['arr_delay']\n",
    "gdf = df.groupby(['origin','dest'])\n",
    "# gdf.first()\n",
    "\n",
    "agdf = gdf.agg({'total_delay':['mean','std','min','max']})\n",
    "print(agdf)\n",
    "\n",
    "#gdf: Imagina que tienes una gran tabla de datos con retrasos de vuelos. Primero, agrupamos esos datos por el lugar de origen y destino de los vuelos, como si hici√©ramos diferentes montones con las fichas de cada vuelo seg√∫n esos dos criterios.\n",
    "\n",
    "#agg: Luego, para cada mont√≥n (grupo) de datos de vuelos, queremos averiguar algunas cosas: el retraso promedio (mean), lo mucho que var√≠an los retrasos (std - desviaci√≥n est√°ndar), el retraso m√°s peque√±o (min) y el retraso m√°s grande (max). Esto lo hacemos con agg.\n",
    "\n",
    "#agdf: Una vez que hemos calculado esas cosas para todos los montones (grupos), tenemos una nueva tabla que muestra estos resultados. Esa tabla nueva es lo que llamamos agdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Escribe un programa Pandas para dividir un conjunto de datos y agruparlos por dos columnas, y luego ordenar los resultados agregados dentro de los grupos.\n",
    "\n",
    "En el siguiente conjunto de datos de vuelos, agrupar \"date\" (fecha completa) y \"carrier\". Luego ordenar la suma de 'total_delay' dentro de los grupos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date        carrier\n",
       "2014-01-01  B6         9383\n",
       "            UA         5897\n",
       "            EV         4675\n",
       "            MQ         3122\n",
       "            WN         2744\n",
       "                       ... \n",
       "2014-10-31  UA         4862\n",
       "            AA         3090\n",
       "            VX           14\n",
       "            HA           -4\n",
       "            F9          -20\n",
       "Name: total_delay, Length: 1520, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "# df.info()\n",
    "\n",
    "gdf = df.groupby(['date', 'carrier']).agg({\"total_delay\": sum})\n",
    "gdf[\"total_delay\"].groupby(level=0, group_keys=False).nlargest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Escribe un programa Pandas para contar el m√∫mero de retrasos de salida por mes y origen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    month origin  delay_count\n",
      "0       1    EWR         4594\n",
      "1       1    JFK         3670\n",
      "2       1    LGA         3261\n",
      "3       2    EWR         3823\n",
      "4       2    JFK         3164\n",
      "5       2    LGA         2590\n",
      "6       3    EWR         3984\n",
      "7       3    JFK         2722\n",
      "8       3    LGA         2851\n",
      "9       4    EWR         3927\n",
      "10      4    JFK         2436\n",
      "11      4    LGA         2671\n",
      "12      5    EWR         3745\n",
      "13      5    JFK         3020\n",
      "14      5    LGA         3102\n",
      "15      6    EWR         4788\n",
      "16      6    JFK         3042\n",
      "17      6    LGA         3375\n",
      "18      7    EWR         4617\n",
      "19      7    JFK         3781\n",
      "20      7    LGA         3192\n",
      "21      8    EWR         4234\n",
      "22      8    JFK         3315\n",
      "23      8    LGA         3046\n",
      "24      9    EWR         2983\n",
      "25      9    JFK         2204\n",
      "26      9    LGA         2160\n",
      "27     10    EWR         3325\n",
      "28     10    JFK         2749\n",
      "29     10    LGA         3058\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supongamos que ya tienes tu DataFrame 'df' con las columnas 'dep_delay', 'origin' y 'month'\n",
    "\n",
    "# Filtrar s√≥lo los vuelos con retraso de salida\n",
    "delayed_flights = df[df['dep_delay'] > 0]\n",
    "\n",
    "# Agrupar por 'month' y 'origin' y contar el n√∫mero de retrasos\n",
    "monthly_delays = delayed_flights.groupby(['month', 'origin']).size().reset_index(name='delay_count')\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(monthly_delays)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Escribe un programa Pandas para cargar los datos de productos y ventas del archivo FoodMarket.xlsx y m√©zclalos en un solo dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (0.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Product', 'Name.x', 'provider', 'Price'], dtype='object')\n",
      "Index(['Code', 'Product', 'Seller', 'Buyer', 'Fecha', 'Quantity'], dtype='object')\n",
      "      Code  Product  Seller  Buyer      Fecha  Quantity              Name.x  \\\n",
      "0        1       15      37     90 2020-11-10        25        Cheese soups   \n",
      "1        2       46      32     51 2020-09-19        16            Pastries   \n",
      "2        3       44      27    166 2019-02-19        25     Moroccan dishes   \n",
      "3        4       52      21     68 2020-06-08        40     Raw fish dishes   \n",
      "4        5       20      21    185 2019-01-18        36               Diets   \n",
      "...    ...      ...     ...    ...        ...       ...                 ...   \n",
      "1496  1497       10      18    199 2020-11-23        34     Breakfast foods   \n",
      "1497  1498       63      58     38 2020-03-13        35               Stews   \n",
      "1498  1499       28       5     81 2020-03-02        31       French dishes   \n",
      "1499  1500       21       2    194 2021-02-18        35  Doughnut varieties   \n",
      "1500  1501       33       8    120 2020-03-13        12       Hors d'oeuvre   \n",
      "\n",
      "      provider      Price  \n",
      "0            1  10.116339  \n",
      "1            2  22.110149  \n",
      "2            2  21.827039  \n",
      "3            3  29.312705  \n",
      "4            1   9.327730  \n",
      "...        ...        ...  \n",
      "1496         1  11.445939  \n",
      "1497         3  29.804814  \n",
      "1498         1  10.879681  \n",
      "1499         1   8.236004  \n",
      "1500         1  11.070380  \n",
      "\n",
      "[1501 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Verificar si el archivo existe\n",
    "file_path = 'FoodMarket.xlsx'\n",
    "if os.path.exists(file_path):\n",
    "\t# Cargar las hojas del archivo Excel\n",
    "\t# Suponemos que las hojas se llaman 'Productos' y 'Ventas'\n",
    "\tProducts = pd.read_excel(file_path, sheet_name='Products')\n",
    "\tPurchases = pd.read_excel(file_path, sheet_name='Purchases')\n",
    "\n",
    "\t# Verificar las columnas disponibles\n",
    "\tprint(Products.columns)\n",
    "\tprint(Purchases.columns)\n",
    "\n",
    "\t# Mezclar los dataframes en base a una columna com√∫n (por ejemplo, 'Product')\n",
    "\t# Aseg√∫rate de que ambas tablas tengan una columna que permita relacionarlas\n",
    "\tmerged_df = pd.merge(Purchases, Products, left_on='Product', right_on='Product', how='inner')\n",
    "\t# Mostrar el dataframe combinado\n",
    "\tprint(merged_df)\n",
    "\n",
    "\t# Guardar el dataframe combinado en un nuevo archivo Excel (opcional)\n",
    "\tmerged_df.to_excel('FoodMarket_Merged.xlsx', index=False)\n",
    "else:\n",
    "\tprint(f\"El archivo {file_path} no se encuentra en el directorio actual.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Escribe un programa Pandas para extraer informaci√≥n sobre el n√∫mero de compras totales y el monto total por nombre de producto y a√±o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (3436468453.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[217], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    ).agg(SumQ=('Quantity',sum), SumTotalPrice=('total-price', lambda x: round(sum(x), 2))\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "#para obtener la vista del precio total deberemos generar una nueva columna de TOTAL PRICE\n",
    "gdf = df.groupby(['ProductName', df['fecha'].dt.year]\n",
    "                 ).agg(SumQ=('Quantity',sum), SumTotalPrice=('total-price', lambda x: round(sum(x), 2))\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('American cheeses', 2019-05-26 00:00:00): [102], ('American cheeses', 2019-06-28 00:00:00): [230], ('American cheeses', 2019-07-26 00:00:00): [1210], ('American cheeses', 2019-08-01 00:00:00): [479], ('American cheeses', 2019-09-10 00:00:00): [157], ('American cheeses', 2019-11-08 00:00:00): [232], ('American cheeses', 2020-01-16 00:00:00): [120], ('American cheeses', 2020-02-16 00:00:00): [1395], ('American cheeses', 2020-03-03 00:00:00): [648], ('American cheeses', 2020-05-05 00:00:00): [107], ('American cheeses', 2020-06-03 00:00:00): [721, 1048], ('American cheeses', 2020-06-06 00:00:00): [1394], ('American cheeses', 2020-06-18 00:00:00): [720], ('American cheeses', 2020-07-13 00:00:00): [1114], ('American cheeses', 2020-08-23 00:00:00): [876], ('American cheeses', 2020-09-17 00:00:00): [1387], ('American cheeses', 2020-11-12 00:00:00): [1232], ('American cheeses', 2020-12-05 00:00:00): [1007], ('American cheeses', 2021-04-04 00:00:00): [1417], ('American cheeses', 2021-04-21 00:00:00): [1140], ('American cheeses', 2021-05-01 00:00:00): [258], ('Appellation d'Origine Contr√¥l√©e cheeses', 2019-01-05 00:00:00): [841], ('Appellation d'Origine Contr√¥l√©e cheeses', 2019-02-19 00:00:00): [904], ('Appellation d'Origine Contr√¥l√©e cheeses', 2019-03-15 00:00:00): [643], ('Appellation d'Origine Contr√¥l√©e cheeses', 2019-03-18 00:00:00): [440], ('Appellation d'Origine Contr√¥l√©e cheeses', 2019-06-07 00:00:00): [750], ('Appellation d'Origine Contr√¥l√©e cheeses', 2019-08-07 00:00:00): [1145], ('Appellation d'Origine Contr√¥l√©e cheeses', 2019-09-12 00:00:00): [728], ('Appellation d'Origine Contr√¥l√©e cheeses', 2019-11-28 00:00:00): [305], ('Appellation d'Origine Contr√¥l√©e cheeses', 2020-02-24 00:00:00): [135], ('Appellation d'Origine Contr√¥l√©e cheeses', 2020-02-28 00:00:00): [1303], ('Appellation d'Origine Contr√¥l√©e cheeses', 2020-04-13 00:00:00): [408], ('Appellation d'Origine Contr√¥l√©e cheeses', 2020-08-03 00:00:00): [519], ('Appellation d'Origine Contr√¥l√©e cheeses', 2020-10-17 00:00:00): [1055], ('Apple cultivars', 2019-01-30 00:00:00): [301], ('Apple cultivars', 2019-02-03 00:00:00): [1120], ('Apple cultivars', 2019-03-03 00:00:00): [1372], ('Apple cultivars', 2019-03-24 00:00:00): [1401], ('Apple cultivars', 2019-04-03 00:00:00): [1119], ('Apple cultivars', 2019-05-11 00:00:00): [753], ('Apple cultivars', 2019-06-14 00:00:00): [242], ('Apple cultivars', 2019-07-01 00:00:00): [158], ('Apple cultivars', 2019-07-15 00:00:00): [1020], ('Apple cultivars', 2019-08-12 00:00:00): [162], ('Apple cultivars', 2019-09-08 00:00:00): [325], ('Apple cultivars', 2019-10-21 00:00:00): [1426], ('Apple cultivars', 2019-12-13 00:00:00): [966], ('Apple cultivars', 2020-01-01 00:00:00): [644], ('Apple cultivars', 2020-05-21 00:00:00): [1380], ('Apple cultivars', 2020-06-16 00:00:00): [782], ('Apple cultivars', 2020-07-01 00:00:00): [24], ('Apple cultivars', 2020-07-03 00:00:00): [1273], ('Apple cultivars', 2020-08-03 00:00:00): [731], ('Apple cultivars', 2020-08-21 00:00:00): [569], ('Apple cultivars', 2020-09-05 00:00:00): [1265], ('Apple cultivars', 2020-09-10 00:00:00): [923], ('Apple cultivars', 2020-10-29 00:00:00): [969], ('Apple cultivars', 2021-01-21 00:00:00): [1402], ('Apple cultivars', 2021-02-05 00:00:00): [1346], ('Apple cultivars', 2021-03-30 00:00:00): [631], ('Apple cultivars', 2021-04-11 00:00:00): [896], ('Bacon dishes', 2019-02-03 00:00:00): [1090], ('Bacon dishes', 2019-02-24 00:00:00): [850], ('Bacon dishes', 2019-04-27 00:00:00): [552], ('Bacon dishes', 2019-05-06 00:00:00): [457], ('Bacon dishes', 2019-06-15 00:00:00): [1096], ('Bacon dishes', 2019-07-06 00:00:00): [1124], ('Bacon dishes', 2019-07-18 00:00:00): [789], ('Bacon dishes', 2019-09-02 00:00:00): [91], ('Bacon dishes', 2019-10-05 00:00:00): [1427], ('Bacon dishes', 2020-06-20 00:00:00): [1278], ('Bacon dishes', 2020-07-31 00:00:00): [650], ('Bacon dishes', 2020-08-12 00:00:00): [1462], ('Bacon dishes', 2020-08-29 00:00:00): [236], ('Bacon dishes', 2020-10-26 00:00:00): [318, 445], ('Bacon dishes', 2020-11-21 00:00:00): [348], ('Bacon dishes', 2020-12-18 00:00:00): [297], ('Bacon dishes', 2021-02-09 00:00:00): [238], ('Bacon dishes', 2021-03-01 00:00:00): [261], ('Bacon dishes', 2021-03-04 00:00:00): [322], ('Bacon dishes', 2021-03-21 00:00:00): [838], ('Bacon dishes', 2021-04-08 00:00:00): [139], ('Bacon dishes', 2021-04-18 00:00:00): [1461], ('Bacon dishes', 2021-05-02 00:00:00): [264], ('Bacon substitutes', 2019-01-08 00:00:00): [1189], ('Bacon substitutes', 2019-01-20 00:00:00): [725], ('Bacon substitutes', 2019-04-14 00:00:00): [535], ('Bacon substitutes', 2019-04-27 00:00:00): [168], ('Bacon substitutes', 2019-05-06 00:00:00): [480], ('Bacon substitutes', 2019-05-07 00:00:00): [692], ('Bacon substitutes', 2019-05-19 00:00:00): [294], ('Bacon substitutes', 2019-05-31 00:00:00): [160], ('Bacon substitutes', 2019-07-05 00:00:00): [822], ('Bacon substitutes', 2019-07-08 00:00:00): [17], ('Bacon substitutes', 2019-07-20 00:00:00): [372, 385], ('Bacon substitutes', 2019-07-29 00:00:00): [674], ('Bacon substitutes', 2019-08-28 00:00:00): [823], ('Bacon substitutes', 2019-09-10 00:00:00): [1182], ('Bacon substitutes', 2019-09-17 00:00:00): [1015], ('Bacon substitutes', 2019-09-20 00:00:00): [1242], ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf = merged_df.groupby(['Name.x', 'Fecha'])\n",
    "gdf.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17814/3621500457.py:2: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  ).agg({'Quantity': sum})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Quantity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name.x</th>\n",
       "      <th>Fecha</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">American cheeses</th>\n",
       "      <th>2019</th>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Appellation d'Origine Contr√¥l√©e cheeses</th>\n",
       "      <th>2019</th>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Vegetables</th>\n",
       "      <th>2019</th>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Vodkas</th>\n",
       "      <th>2019</th>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Quantity\n",
       "Name.x                                  Fecha          \n",
       "American cheeses                        2019        183\n",
       "                                        2020        384\n",
       "                                        2021         97\n",
       "Appellation d'Origine Contr√¥l√©e cheeses 2019        241\n",
       "                                        2020        184\n",
       "...                                                 ...\n",
       "Vegetables                              2019        249\n",
       "                                        2020        108\n",
       "Vodkas                                  2019        348\n",
       "                                        2020        187\n",
       "                                        2021         66\n",
       "\n",
       "[205 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf = merged_df.groupby(['Name.x', merged_df['Fecha'].dt.year]\n",
    "                ).agg({'Quantity': sum})\n",
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aseg√∫rate de que la columna de fecha est√© en formato datetime\n",
    "merged_df['Fecha'] = pd.to_datetime(merged_df['Fecha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer el a√±o de la fecha\n",
    "merged_df['year'] = merged_df['Fecha'].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar por 'Name.x' y 'year' para calcular:\n",
    "# 1. N√∫mero total de compras (conteo)\n",
    "# 2. Monto total de las ventas (suma)\n",
    "summary = merged_df.groupby(['Name.x', 'year']).agg(\n",
    "    total_purchases=('Name.x', 'count'),  # Conteo del n√∫mero de compras\n",
    "    total_amount=('Price', 'sum')  # Suma del monto de las compras\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Name.x  year  total_purchases  \\\n",
      "0                           American cheeses  2019                6   \n",
      "1                           American cheeses  2020               13   \n",
      "2                           American cheeses  2021                3   \n",
      "3    Appellation d'Origine Contr√¥l√©e cheeses  2019                8   \n",
      "4    Appellation d'Origine Contr√¥l√©e cheeses  2020                5   \n",
      "..                                       ...   ...              ...   \n",
      "200                               Vegetables  2019                7   \n",
      "201                               Vegetables  2020                4   \n",
      "202                                   Vodkas  2019               13   \n",
      "203                                   Vodkas  2020                7   \n",
      "204                                   Vodkas  2021                2   \n",
      "\n",
      "     total_amount  \n",
      "0       53.481556  \n",
      "1      115.876704  \n",
      "2       26.740778  \n",
      "3       85.645240  \n",
      "4       53.528275  \n",
      "..            ...  \n",
      "200    259.493442  \n",
      "201    148.281967  \n",
      "202    525.258332  \n",
      "203    282.831410  \n",
      "204     80.808974  \n",
      "\n",
      "[205 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el resultado\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los resultados en un archivo Excel (opcional)\n",
    "summary.to_excel('Product_Purchase_Summary.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Code  Product  Seller  Buyer      Fecha  Quantity              Name.x  \\\n",
      "0        1       15      37     90 2020-11-10        25        Cheese soups   \n",
      "1       79       15      42    205 2020-07-28        26        Cheese soups   \n",
      "2      164       15      55    101 2020-11-11        46        Cheese soups   \n",
      "3      196       15      15    121 2021-03-15        40        Cheese soups   \n",
      "4      291       15      15    174 2019-12-13        45        Cheese soups   \n",
      "...    ...      ...     ...    ...        ...       ...                 ...   \n",
      "1496  1176       21      36     79 2019-11-26        28  Doughnut varieties   \n",
      "1497  1326       21      21    114 2020-09-27        39  Doughnut varieties   \n",
      "1498  1414       21      19     76 2019-03-25        31  Doughnut varieties   \n",
      "1499  1442       21      49     23 2020-04-20        27  Doughnut varieties   \n",
      "1500  1500       21       2    194 2021-02-18        35  Doughnut varieties   \n",
      "\n",
      "      provider      Price  year  \n",
      "0            1  10.116339  2020  \n",
      "1            1  10.116339  2020  \n",
      "2            1  10.116339  2020  \n",
      "3            1  10.116339  2021  \n",
      "4            1  10.116339  2019  \n",
      "...        ...        ...   ...  \n",
      "1496         1   8.236004  2019  \n",
      "1497         1   8.236004  2020  \n",
      "1498         1   8.236004  2019  \n",
      "1499         1   8.236004  2020  \n",
      "1500         1   8.236004  2021  \n",
      "\n",
      "[1501 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el dataframe combinado\n",
    "print(merged_df)\n",
    "\n",
    "# Guardar el dataframe combinado en un nuevo archivo Excel (opcional)\n",
    "merged_df.to_excel('FoodMarket_Merged.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
